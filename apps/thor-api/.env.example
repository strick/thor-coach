# Thor API Environment Configuration

# Server Port
# Default: 3000
PORT=3000

# LLM Configuration
# Choose either Ollama (local) or OpenAI (cloud) for workout parsing

# Option 1: Ollama (Local LLM)
# Set to "true" to use Ollama instead of OpenAI
USE_OLLAMA=true
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Option 2: OpenAI (Cloud LLM)
# If USE_OLLAMA is not true and OPENAI_API_KEY is set, will use OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o-mini

# Note: If both are configured, USE_OLLAMA=true takes precedence
